% Chapter Template

\chapter{Background Theory} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
Localization systems come with various architectures and system designs. Several different methodologies can be applied to estimate the targets current position. In this chapter we distinguish between client and server-based system architectures. We introduce fingerprinting-based and range-based localization techniques, as well as the principles of movement detection. The process of information fusion from different data sources and the radio technology of ultra wideband is explained in the last part of this section.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\section{Client and Server-based Localization}
For many applications the system architecture is very important. The environmental conditions, the underlying hardware and also dogmatic thoughts are taken into account for real applications to determine the system architecture. There are two main types of system architectures - client-based or server-based - that can be distinguished. However, systems using computational resources of client and servers are possible, where a clear distinction is no longer possible.\\
\noindent\hspace*{5mm}%
Client-based architectures have the huge advantage, that no additional server hardware is needed. The client device collects data used for the localization and processes it, to estimate its own position. A client-based localization should be used when standardized target devices with enough computational power and enough energy supply are localized. As all computations are done on the device itself, no further communication to a seperated server is needed. This ensures that no other application can access the position estimation and reduces the communication overhead.\\
\noindent\hspace*{5mm}%
A server-based system however, can be more powerful and computationally complex than client-based systems, as there are no big hardware restrictions. The application itself runs on a centralized server, whereas the client-device is only involved in the data collection process. The requirements of the client-hardware shrink to a minimum, which allows also to use different, non-standardized, devices as target. Especially when position estimations are not used in applications running on the target device, a server-based architecture is beneficial. Often, multiple targets are tracked, which is easily possible with a centralized server approach, as the data of several target devices is directly available on the server and can be further processed. 


%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------
\section{Fingerprinting Localization Technique}
Fingerprinting Localization, also known as radio map based technique, use a dense positioning of anchor nodes in the indoor area of interest. A set of measurements, often received signal strength information (RSSI), serve as a fingerprint at each location. Measurments are not limited to radio signals, other sources such as magnetic field data can also be used. The more unique these measurements are, the better is the localization accuracy. Fingerprinting often consists of an offline phase to generate the radio map and an online phase to retrieve the position with a given fingerprint.\\
\noindent\hspace*{5mm}%
In the offline phase, a radio map is generated with several fingerprints. The radio map can either consist of different fingerprint measurements at given reference points (landmarks) that are interpolated to the whole area, or of fingerprints measured in predefined zones in the area of interest. After this phase, for every location in the grid, a tupel (location, fingerprint) with a unique fingerprint should be available.\\
\noindent\hspace*{5mm}%
The online phase consists of an observed fingerprint at the targets location, on which the localization algorithm can be applied to associate the fingerprint to similar radio map entries. This association is then used to estimate the targets location. The result can either be a concrete position estimation built on the presence of reference points or it can be a probability of the target being in a recognized zone. 

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Range Based Localization}

Range based localization systems are depending on an infrastructure in the area of the localization:
\begin{itemize} 
\item \textbf{Target Node (TAG)} which is the device that is localized. 
\item \textbf{Anchor Nodes (AN)} that are placed on carefully chosen points in the building, to encounter the best coverage of the whole area.
\end{itemize}

The key idea of range based positioning is to measure the distance between TAG and ANs. With the use of these distances, the exact position of the TAG can be evaluated using multilateration or similar mathematical models. Several different approaches are possible to determine the distance to an anchor node, they can be classified into two groups. In the one hand there are algorithms using propagation models, which rely on the reduction in power density of electromagnetic waves propagating through space. In the other hand, algorithms make use of known propagation velocities for radio signals  by measuring the time of flight of transmitted waves. 

%-----------------------------------
%	SUBSECTION 3.1
%-----------------------------------
\subsection{Propagation Models}
An electromagnetic wave loses power density when travelling through space. In free space, formula \ref{eqn:freePathLoss} explains the relationship between distance and signal strength \cite{VorlesungCN}.

\begin{equation}
P_{r} = P_{t} (\lambda/4\pi r)^2
\label{eqn:freePathLoss}
\end{equation}

where $P_{r}$ is the received signal strength and $P_{t}$ the transmitted signal strength. $\lambda$ is the wavelength and $r$ the radius, or in other words the distance from transmitter to receiver. As this formula is restricted to free-space and often in real indoor environments various kind of obstacles are present, several other approximations for the relationship between distance and signal power exist. Many indoor positioning algorithms use received signal strength indication (RSSI) to calculate distances to the anchor nodes. Mainly because RSSI can be applied to almost every type of transmitted signal, thus RSSI uses universal applicable theory. Two approximations are widely used to take care of the non-free-space environments indoors.\\
\noindent\hspace*{5mm}%
A commonly used model for the relationship of distance and RSS is known as Log-normal Distance Path Loss (LDPL), where the path loss in Decibel (dB) is defined as \cite{Sarkar}:
\begin{equation}
PL = PL_{0} +10 \gamma log_{10} (\frac{d}{d_{0}}) + X_{g}
\label{eqn:LDPL}
\end{equation}

with $\gamma$ as the path loss exponent, $PL_{0}$ a path loss measurement at reference distance $d_0$ and $X_{g}$ a zero-mean Gaussian noise. This generic model can be applied to many different environments. It can even be simplified by defining useful reference distances, like done in \cite{Kurt}.\\
\noindent\hspace*{5mm}%
LDPL has shown to be rather inaccurate for indoor environments, which led to a path loss model based on Non-Linear Regression (NLR) as used in \cite{ZanLi}. In this approach, the distance to RSS relationship is modelled with the equation:
\begin{equation}
d_{i} = \alpha_{i} e^{\beta_{i}RSS_{i}}.
\label{eqn:NLR}
\end{equation}
$d_{i}$ is the distance between the $i$-th AN and the TAG, $RSS_{i}$ the measured signal strength at the $i$-th AN and $\alpha_{i}$, $\beta_{i}$ specific coefficients obtained in the area of interest. These two coefficients are rather important for the performance of this approach. They are defined due to extensive calculations based on preliminary measuements as described in \cite{Kurt}.


%-----------------------------------
%	SUBSECTION 3.2
%-----------------------------------
\subsection{Time of Flight Based Models}
A totally different technique to get distance estimations are time of flight based models. Their key idea is that we know the travelling velocity of radio waves, which is approximately the speed of light (\SI{2.99792458e8}{\meter\per\second}). When measuring the time between sending and receiving a radio signal, we can easily convert this time of flight (ToF) to a distance estimation. Time of flights are determined by gathering round trip times (RTT) in radio signal communication. For accurate RTT results the hardware of transmitter and receiver, as well as the operating firmware are very important. For the two presented RTT-measuring techniques, the key characteristics are either a quick responding time or extremely well synchronized sender and receiver.\\
\noindent\hspace*{5mm}%
Two way ranging (TWR) is one of these methods to retrieve an accurate round trip time. An illustration of the TWR process can be seen in figure \ref{fig:two_way_ranging}. When operating in TWR mode, the TAG sends a message to the ANs and registers the exact time of sending. As soon as the message arrives at its destination, the firmware of the AN instantly captures another timestamp. In an acknowledgement (ACK) message, the timestamp of reception and a timestamp of sending the response is transmitted. When this message arrives at the TAG, again a timestamp is registered. With equation \ref{eqn:TWR}, the time of flight can now be evaluated \cite{SewioTWR}.

\begin{figure}[th]
\centering
\includegraphics[width=0.5\textwidth]{Figures/two_way_ranging}
\decoRule
\caption[Two Way Ranging]{Illustration of TWR and SDS-TWR communication}
\label{fig:two_way_ranging}
\end{figure}

To achieve higher accuracy, the communication can be extended with a final message containing two additional timestamps of the requester. This is called symmetrical double-sided two-way ranging (SDS-TWR) \cite{Wikipedia} and is indicated as optional in Figure \ref{fig:two_way_ranging}.\\
\\
Evaluation of time of flight for TWR:\\
\begin{equation}
 ToF = [(T_{RA}-T_{SP})-(T_{SA}-T_{RP})] / 2
\label{eqn:TWR}
\end{equation}

Respectively the time of flight for SDS-TWR:\\
\begin{equation}
ToF = [(T_{RA}-T_{SP})-(T_{SA}-T_{RP}) + (T_{RF}-T_{SA})-(T_{SF}-T_{RA}) ]/ 4
\label{eqn:SDS-TWR}
\end{equation}

with the following timestamps, also indicated in figure \ref{fig:two_way_ranging}: $T_{SP}$ as time of poll-sending, $T_{RP}$ as time of poll-reception, $T_{SA}$ as time of ACK-sending, $T_{RA}$ as time of ACK-reception, $T_{SF}$ as time of Final-sending and $T_{RF}$ as time of Final-reception.\\
\noindent\hspace*{5mm}%
A second approach for RTT determination is called time difference of arrival (TDOA). While TWR does not need further synchronization between the devices, TDOA requires a very precise synchronization of the anchor nodes. This is normally done by specifying a master node per three to five anchors. For bigger scenarios often multiple dedicated masters will send clock synchronizations every once in a while, such that every AN gets at least one sync package. It occurs as well that an anchor holds two differently synchronized times.
To evaluate the time of flight, a TAG in range will broadcast a blink message. This blink message will initialize the ranging process. Every AN that receives this blink, will capture a timestamp of the time of arrival (or when holding more than one synctime, capture multiple timestamps). These timestamps are forwarded to the server together with a synch ID and a blink transmitter identity. When a server received at least three timestamps with the same synch ID, it can perform the position and therefore the distance estimation based on the time of arrival of the initial blink message at each AN.
\begin{figure}[th]
\centering
\includegraphics[width=0.7\textwidth]{Figures/time_difference_of_arrival}
\decoRule
\caption[Time Difference of Arrival]{Typical Setup for Time Difference of Arrival communication}
\label{fig:time_difference_of_arrival}
\end{figure}
A huge benefit of TDOA is the fact, that the TAG only needs to send one blink message per timeinterval and will not have to communicate with every AN separately, as in TWR. This can be seen in figure \ref{fig:time_difference_of_arrival}.\\
\noindent\hspace*{5mm}%
For TWR the overhead grows enourmous with every anchor and every TAG that is added. For TDOA hundrets of TAGs can be tracked, with only proportional overhead growth and much lower energy consumption for the TAG.\\
Number of messages sent in one iteration:\\
TWR:  $3 * n_{t} * n_{an}$\\
TDOA:  $n_{t}$\\
Where $n_{t}$ is the number of TAGs and $n_{an}$ is the number of anchor nodes \cite{SewioTDOA}.

%-----------------------------------
%	SUBSECTION 3.3
%-----------------------------------
\subsection{Multilateration}
Multilateration is a mathematical method to calculate a position using three or more known distances. It is an extention of trilateration, where only three distances are used. Triagulation and trilateration use the mathematical concepts of triangles to find unknown lengths. Triangulation was already mentioned by the greek mathematician Thales, who used this concept for finding out the height of ancient egypt pyramids \cite{thales}. It was also used for cartography purposes, where angles between fixed points were measured and heights and distances could be calculated. 
Although trilateration and triangulation use the same mathematical triangle concept, they have one defined difference: We call it triangulation, when angles to anchor positions are measured, otherwise - when distances to anchors are measured - it's called trilateration.
As it was easier to measure angles than distances in the past, triangulation was more often used. With modern electronic devices, it is more common to determine distances, rather than angles. 

\begin{figure}[th]
\centering
\includegraphics[width=0.6\textwidth]{Figures/trilateration}
\decoRule
\caption[Trilateration]{Graphical illustration of the trilateration concept.}
\label{fig:trilateration}
\end{figure}

Figure \ref{fig:trilateration} shows how trilateration is used for positioning. With the known distance to every AN, a circle with radius of this distance can be drawn around every AN. These circles do only have one common intersection point, that is where the TAG lies. However, this is a theoretical and idealized scenario, where every range can be determined accurately. In real applications, the ranges are not exactly calculated, what leads to the fact that we will not only get a single point for the calculated position, but several points, especially when we use more than three ANs.

%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------
\section{Movement Detection}
Indoor positioning is often reduced to two dimensions, such that the movement vector is also a two dimensional construct. A movement vector $Mv_{t}$ can be stored as $(X_{t}, Y_{t})$ cartesian coordinates or using a tuple of heading direction angle and stride length $(\theta_{t}, \ell_{t})$. Both of $\theta$ and $\ell$ can be calculated by the IMU readings, where several noises occur such that the heading direction is statistically described as:
\begin{equation}
\theta_{t} = \hat{\theta}_{t} + \theta_{bs,t} + \theta_{be,t} + \epsilon_{\theta, t},
\label{eqn:heading_direction}
\end{equation}
with $\hat{\theta}_{t}$ as the actual heading orientation,  $\theta_{bs,t}$ as a sensor bias introduced by uncalibrated sensor readings, $\theta_{be,t}$ as an environmental angular bias due to magnetic field disturbances and $\epsilon_{\theta, t}$ as a measured random error. The heading direction can be calculated by using the geomagnetic field of the earth. The formula $\theta = atan(\frac{mag_{x}}{mag_{y}})$ can be used to obtain the heading direction, where $mag_{x}$ and $mag_{y}$ are the magnetic field sensor readings in X direction, respectively in Y direction.\\
\noindent\hspace*{5mm}%
Whereas the heading direction is obtained by measuring absolute values of magnetic field energy, the accelerometer data is a relative quantity, that is used for stride length determination. Dealing with relative values, measured errors propagate over time, so it is almost impossible to use relative quantities (e.g. acceleration) to calculate absolute quantities (e.g. distance) over a longer period of time. To address this, an absolute quantity is needed to correct long term errors. Velocities from previous time slots can be used for this. As we can not assume the acceleration to be constant during a whole time slot, the movement length approximation can be defined as: 
\begin{equation}
\ell_{t} = \hat{\ell}_{t-1} + \sum_{i=0}^{N}([(\hat{a}_{i} + a_{bs,i} +\epsilon_{a, i}) * \Delta t_{i} ]*(N-i)) *\Delta t + \epsilon_{\ell, t},
\label{eqn:stride_length}
\end{equation}
where $\hat{\ell}_{t-1}$ is the actual movement length of time period $t-1$, $\hat{a}_{i}$ is the actual middle acceleration during the $i$-th of N time slots in time period $\Delta t$, $a_{bs,i}$ is an other sensor bias due to uncalibrated sensor readings and $\epsilon_{a, i}$ as well as $\epsilon_{\ell, t}$ are measured random errors in acceleration and distance respectively.


%----------------------------------------------------------------------------------------
%	SECTION 5
%----------------------------------------------------------------------------------------

\section{Data Fusion for Localization}
When several different sources of data are collected and brought together in one algorithm, we call it data fusion. There are several common ways of fusing data, the most widely used are filtering approaches such as the Kalman Filter \cite{Kurt} and the Particle Filter. The focus of this work lies on a particle filter approach, also known as Monte Calro Localization (MCL), which is often used fo indoor positioning. It combines various noisy measurements to estimate the system state and minimize errors. To introduce the particle filter, we explain its three main phases and the corresponding inputs. 

\subsection{Particle Filter: Prediction Phase}
In the prediction phase, every particle is repositioned. At time $t$, each particle has a state vector that is defined as follows:
\begin{equation}
X_{t} = [x_{t}, y_{t}, x_{t-1}, y_{t-1}],
\label{eqn:particles}
\end{equation}
where $(x_{t}, y_{t})$ corresponds to the Cartesian coordinates of the particle at time $t$ and $(x_{t-1}, y_{t-1})$ at time $t-1$ respectively. The repositioning of the particles is often done randomly, however, it could also be done according to the movement vector or other sensor-based values. If present, floorplan restrictions are applied in this phase, whereas movements through walls are not permitted, they lead to another prediction iteration for that particle.

\subsection{Particle Filter: Observation Phase}
In the observation phase the associated particle weight $w^{i}_{t}$ is recalculated for every particle, since the weight does not anymore correspond to the current position. For each anchor node, we have an obtained distance measurement $d^{j}_{t}$, which itself consists various errors. Statistically it can be described as: 
\begin{equation}
d^{j}_{t} = \hat{d}^{j}_{t} + d^{j}_{be, t} + \epsilon_{d^{j}, t},
\label{eqn:distances}
\end{equation}
where $\hat{d}^{j}_{t}$ is the actual distance to node $j$, $d^{j}_{be, t}$ is an environmental bias due to local conditions and $\epsilon_{d^{j}, t},$ is a measured random error.\\
\noindent\hspace*{5mm}%
The weight is updated corresponding to the likelihood of the range observations conditioned on each particle $p(Zd_{t} | X^{i}_{t})$ at time t, respectively the likelihood of the motion observation conditioned on each particle $p(Mv_{t} | X^{i}_{t})$ at time t. With the defined observation vector $Zd_{t} = [d_{t}^{j}], j = 1...N$, at time $t$, where $N$ is the number of
ANs.


 Then, the probabilities are determined as:
\begin{equation}
p(Zd_{t} | X^{i}_{t}) = p(d_{t}^{j} | X^{i}_{t})
\label{eqn:probability_distance}
\end{equation}
and
\begin{equation}
p(Mv_{t} | X^{i}_{t}) = p(M_{x,t} | X^{i}_{t}) * p(M_{y,t} | X^{i}_{t}).
\label{eqn:probability_movement}
\end{equation}
In addition, the zone probability is:
\begin{equation}
p(y_t | X^{i}_{t}) = p_{tot}(y_{t} | z^{i}_{t}),
\label{eqn:probability_zone}
\end{equation}
where $y_t$ is the observed fingerprint at time $t$ and $z^{i}_{t}$ the current zone of particle $X^{i}$.
In order to avoid confusion between different likelihoods used in this work, hereafter we refer to $p(d_{t} | X^{i}_{t})$ as the ranging likelihood, $p(M_{t} | X^{i}_{t})$ for the motion likelihood, $p(y_t | X^{i}_{t})$ for the zone likelihood and $p(Z_{t} | X^{i}_{t})$ as the overall likelihood.

The associated weight $w^{i}_{t}$ of each particle is given by ranging as well as by motion information. A particle at the current position $(x_{t},y_{t})$ with low probability to observe $d_{t}^{j}$ in its position will be assigned a small weight. Additionally a particle that moved in x-direction by $x_{t}^{i}-x_{t-1}^{i}$ with low probability to observe the movement $M_{x,t}$ will also be assigned a small weight. Analogue for the movement in y-direction.
That leads to the fact that particles with large weights will have a stronger effect to the determination of the state of the system.
We assume that all these likelihoods - the ranges to each AN as well as the movement in direction x, y - are statistically independent from each other. Therefore, the overall likelihood is defined as:
\begin{equation}
p(Z_{t} | X^{i}_{t}) = \prod_{j=1}^{N} p(\hat{d}_{j,t}|X_{t}^{i}) * p(\hat{M}_{x,t} | X^{i}_{t}) * p(\hat{M}_{y,t} | X^{i}_{t}) * p(y_t | X^{i}_{t}),
\label{eqn:probability_overall}
\end{equation}
where $\hat{d}_{j,t}$ is the measured distance to the AN j at time t and $\hat{M}_{x,t}$ is the measured motion in x-direction in timeinterval t, respectively $\hat{M}_{y,t}$ in y-direction and $y_t$ is the measured RSS fingerprint.

The individual likelihood for the range observation can then be expressed as:
\begin{equation}
p(\hat{d}_{j,t} | X^{i}_{t}) = \frac{1}{\sqrt{2\pi \sigma_{j}^{2}}} * exp(\frac{-[\sqrt{(x^{i}_{t}-x_{j})^{2}+(y^{i}_{t}-y_{j})^{2}} - \hat{d}_{j,t}]^{2}}{2\sigma_{j}^{2}}),
\label{eqn:probability_individual_distance}
\end{equation}
where $(x_{j},y_{j})$ are the known coordinates of the $j$-th AN.
Whereas the individual likelihood of the motion observation in x-direction (analogue for y-direction) is expressed as follows:

\begin{equation}
p(\hat{M}_{x,t} | X^{i}_{t}) = \frac{1}{2\pi \sigma_{Mx}^{2}} * exp(\frac{-[(x^{i}_{t}-x^{i}_{t-1}) - \hat{M}_{x,t}]^{2}}{2\sigma_{Mx}^{2}})
\label{eqn:probability_individual_movement}
\end{equation}

\subsection{Particle Filter: Resampling Phase}
The resampling phase is an essential component of a particle filter implementation, although it is a computationally expensive step. In the resampling, particles with low assigned weights are repositioned at identical positions as particles with high associated weights. This means, that after the repositioning of the prediction phase and after the weight calculation in the observation phase, a resampling in systematic manner is done. This resampling relies on the overall likelihood $p(Z_{t} | X^{i}_{t})$, which means that every kind of likelihood is taken into account for this step. After repositioning the particles with low weights (and updating their weight), all weights are normalized to obtain in the next step the weighted center of all particles, which corresponds to the estimated position. 

%----------------------------------------------------------------------------------------
%	SECTION 6
%----------------------------------------------------------------------------------------


\section{Ultra Wideband Radio Technology}
Ultra wide-band (UWB) is a radio technology in use for military and industrial communication, positioning and collecting sensor data. Unlike other communication technologies, UWB occupies a wide area of frequencies instead of just covering a small frequency spectrum. As shown in figure \ref{fig:frequency_spectrum}, UWB spans over a spectrum of more than 500 megahertz (MHz) that lies within the range of 3.1 gigahertz (GHz) and 13.6 GHz.
\begin{figure}[th]
\centering
\includegraphics[width=1.0\textwidth]{Figures/frequency_spectrum}
\decoRule
\caption[UWB Frequency Spectrum]{Comparison of Wi-Fi (802.11) and UWB frequencies.}
\label{fig:frequency_spectrum}
\end{figure}
UWB opperates with less energy compared to other communication like Wi-Fi. However, the main difference between UWB and conventional radio transmissions is the underlying modulation technique. UWB transmits data by generating short radio energy at specific times instead of varying frequency and phase of sinus waves. In addition to the pulse position, the pulses can carry information either by their polarity, their amplitude or by using orthogonal pulses.
A single pulse is kept as short as possible, such that more than 100 Million, sometimes even continuous streams with more than 1 Billion pulses per second are generated. As single pulses can be registered and identified by the receiver, UWB devices are able to determine very exact ToFs such that distance estimations can be done to high resolution.\\
\noindent\hspace*{5mm}%
The pulse rate highly influences the transmission rate of an UWB communication. The pulse frequency varies between 1 million pulses per second to over 1 billion pulses. Devices often support different operation modes, such that the number of pulses can be configured. However, with a higher pulse rate, the transmitting distances decreases, such that a trade-off between datarate and communication distance occurs. In table \ref{tab:pulse_rate_range} the approximate correlation between pulse rate, bit rate and range is shown \cite{ITU}. In a cluttered environment, especially for non line of sight communications, the possible communication distance decreases very fast. This has to be concerned for indoor applications, as line of sight is very rare in an indoor scenario.

\begin{table}
\caption{Relationship of Pulse Rates and Communication Distance}
\label{tab:pulse_rate_range}
\centering
\begin{tabular}{c c c}
\toprule
\textbf{Pulse rate}[pulse/s] & \textbf{Bit rate}[Mbit/s] & \textbf{Range}[m]\\
\midrule
1'000'000 & \textasciitilde40 & \textasciitilde100\\
500'000'000 & \textasciitilde100 & \textasciitilde10\\
1'000'000'000 & \textasciitilde500 & 4-10\\
\bottomrule\\
\end{tabular}
\end{table}








