% Chapter Template

\chapter{Implementation and experiment setup} % Main chapter title

\label{Chapter4} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
In this section we explain in detail, what hardware we used in our implementation and with which technology the UWB communication and ranging was done. Then we introduce the zone indication learning algorithm and finally we briefly explain the core of our work, the mathematical theory of the particle filter.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Hardware}
We decided to use Raspberry Pis for all mobile devices such as the TAG and the ANs. As the Raspberry Pis were not equipped with UWB technology, we extended them with a SEQUITUR Pi board from UNISET company running InGPS Lite firmware. In the following two subsections we present you these two hardware components.

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------

\subsection{Raspberry Pi}
A Raspberry Pi is a single-board computer not much bigger than a credit card. Raspberry Pis are mainly designed for educational purposes as an alternative to expensive notebooks or desk computers. Hence the focus lies also on easy-to-use and plug-and-play experiences. Raspberry Pis are useful for versatile types of projects, as they provide common state of the art hardware - like HDMI, USB and wireless LAN - direct on boad and as they are extendable with selected components.

We used Raspberry Pi Model B \cite{Raspberry}, these were the most relevant specifications for our work:
\begin{itemize}
\item Quad Core 1.2GHz Broadcom BCM2837 64bit CPU
\item 1GB RAM
\item BCM43438 wireless LAN
\item 100 Base Ethernet
\item 40-pin extended general purpose input output (GPIO)
\item Micro SD port for loading your operating system and storing data
\end{itemize}

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{SEQUITUR Pi board with InGPS Lite}
On the 40-pin extended GPIO, we connected the SEQUITUR Pi board from UNISET Company. UNISET is a company located in Italy that focuses on research, development and manufacturing of innovative sensors in two major application areas \cite{Uniset}:

\begin{itemize}
\item Access control security systems, enhancing the reliability of intrusion detection
\item Indoor and outdoor tracking. Sequitur is a precise real time locating system (RTLS) for tracking any object in 2D or 3D with centimeter accuracy.
\end{itemize}

This hardware seemed perfect for our ambitions, as it provides a state-of-the-art UWB communication and ranging. Moreover the SEQUITUR Pi board of the TAG has IMU sensors like 3D-accelerometer and 3D-magnetometer on board. Together with the hardware, UNISET delivers a firmware running on Raspberry Pis operating system (OS) to establish a connection via user datagram protocol (UDP). This firmware allows to communicate with the sensors in order to retrieve IMU sensor data, but also to get direct access to the range between two nodes. It is explained in detail throughout the next section. 

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{UWB Communication and Ranging}
The radio module of SEQUITUR Pi board is used on the one hand to transmit data - in order to obviate the need for additional communication hardware - and on the other hand to evaluate the ToF. As UNISET is a comercial company, they do not provide full information of the underlying transmission techniques. Nonetheless in the two following subsections, the known parts are mentioned.

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Transmission}
SEQUITUR InGPS Lite enables single-hop wireless communication with the UWB interface between neighboring nodes of the same network. 
The radio module supports six different user-selectable frequency bands between 3.5 GHz and 6.5 GHz. There are six different operation modes to change the spectral occupation, listed in the table below:\\
\\
\begin{tabular}{c c c}
Channel Number  & Central Frequency [MHz] & Bandwidth [MHz]\\
1 & 3494.4 & 500\\
2 & 3993.6 & 500\\
3 & 4492.8 & 500\\
4 & 3993.6 & 1300\\
5 & 6489.6 & 500\\
7 & 6489.6 & 1100\\
\end{tabular}
\\
\\
The data rate can be changed to three preset values of 110 kilobit per second (kbps), 850 kbps and 6.8 megabit per second (Mbps). All nodes have to operate in the same radiomode to communicate correctly. A lower data rate allows lager operating distances between the nodes. 
The default pulse repetition frequency (PRF) is assumed to 64 MHz for all the channels.
The underlying modulation techniques are not indicated in the specifications \cite{Usermanual} \cite{Beginnersguide}.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Ranging with TWR}
UNISET company offers two different packages for positioning. InGPS Lite, which is the standard software and InGPS Pro, which is the advanced package. For our implementation InGPS Lite was sufficient, as the main difference of the two packages are the number of TAGs and anchors supported. With InGPS Lite only one TAG and a maximum of 10 anchors are supported as with InGPS Pro numerous TAGs and anchors are possible. InGPS Lite opperates only in TWR mode other than InGPS Pro, where a second mode with TDOA range estimation is available.
The range estimation of two nodes is triggered by the application programming interface (API) command $CLIENT\_GET\_RANGE\ (50)$. In our application we sent the command to the anchor in order to minimize the communication of the TAG. The flow of actions related to this API is a even more simplified version of the message exchange indicated in figure \ref{fig:two_way_ranging}. In our case, the request message performed by the client starts the TWR conversation via UWB between AN and TAG. The AN sends only one ranging request to the TAG, which immediately responds. By observing the difference between the time instants related to the transmission of the request packet and the reception of the response packet, the AN will directly determine the RTT and thus the range. Finally an answer message with the range is reported from the AN to the client and no messages are reported from the TAG to the client.


%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Zone Indication: Descriminative Ensemble Learning with Hidden Markov Models}
The zone indication is a rather complex and computationally demanding process, thus we will expain it to higher detail than the other inputs of the particle filter. The zone indication fuses Wi-Fi, UWB, magnetic field (MF) and room transition information in an enhanced learning model. A set of independent individual machine learning methods are combined in an ensemble learning model. The used approach integrates Hidden Markov Model (HMM) with discriminative learning techniques as presented in an earlier work of CDS \cite{Carrera2}.

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{HMM-Discriminative Ensemble Learning Method}
In this approach different machine learning algorithms are combined to improve the zone prediction result. A zone can be defined as any subarea in the area of interest (e.g. a room). In the concept of Markov localization \cite{Markov}, the state of the system is estimated by the state transitions. For localization, the states of the model correspond to defined zones.
Therefore, the HMM is specified by the following components, as in \cite{Carrera2}:
\begin{itemize}
\item A set of $n$ states $Z=\{z_{1}, z_{2},\dots,z_{n}\}$, with $z_{i}$ as the identifier value of the zone $i$. Resulting the descrete random variable $x_{t} \in Z$ representing the hidden state at time t.
\item A quadratic matrix $A$ holding the transition probabilities,
\begin{equation*}
A = 
\begin{pmatrix}
   a_{1,1} & a_{1,2} & \dots & a_{1,n}\\
   a_{2,1} & a_{2,2} & \dots & a_{2,n}\\
    \vdots & \vdots & \ddots & \vdots  \\
   a_{n,1} & a_{n,2} & \dots & a_{n,n}\\
\end{pmatrix},
\end{equation*}
where $a_{ij}$ respresents the probability of moving from zone $z_{i}$ to zone $z_{j}$.
\item A set of observations O, defined as:
$$O = \{(o_{1},o_{2},\dots,o_{m})_1, \dots, (o_{1},o_{2},\dots,o_{m})_r\}$$
where $o_{i}$ stands for the zone prediction result of the $i$-th individual machine learning algorithm. This leads to $O$ being a set of $^rP_m$ permutations (repetitions allowed), with $r$ being the number of zones and $m$ the number of different machine learning algorithms. The machine learning methods have to be conditionally independent for $y_{t} \in O$ as the random variable of the observations in time $t$.
\item A matrix $B$ holding the emission probabilities of observation likelihoods:
\begin{equation*}
B = 
\begin{pmatrix}
   b_{1,1} & b_{1,2} & \dots & b_{1,r}\\
   b_{2,1} & b_{2,2} & \dots & b_{2,r}\\
    \vdots & \vdots & \ddots & \vdots  \\
   b_{n,1} & b_{n,2} & \dots & b_{n,r}\\
\end{pmatrix},
\end{equation*}
where $b_{ij}$ respresents the probability of $(o_{1},o_{2}, \dots, o_{m})_j$ being the observation generated in zone $z_{i}$.
\item An initial probability distribution $\pi = \pi_{1},\pi_{1},\dots, \pi_{n}$ over the $n$ zones.
\end{itemize}
How the specified components interact in the HMM can be seen in figure \ref{fig:hidden_markov_model}.


\begin{figure}[th]
\centering
\includegraphics[width=0.8\textwidth]{Figures/hidden_markov_model}
\decoRule
\caption[HMM]{Application of the different probabilistic parameters in the hidden markov model.}
\label{fig:hidden_markov_model}
\end{figure}

The learning of each individual machine learning method only relies on the fingerprint of Wi-Fi, UWB and magnetic field, that's why prediction errors can still occur. However we can integrate the zone transition information (e.g. some areas are only reachable through other areas) in the HMM to improve the prediction. To determine the sequence of variables that is underlying source of some sequence of observation in a model with hidden variables, a decoding task is necessary. With the HMM model $\lambda = \{\pi, A, B\}$ and the given observation sequence $y_{t-i},\dots, y_{t-1},y_{t}$, the Viterbi algorithm \cite{Viterbi} is used to estimate the hidden states sequence $x_{t-i},\dots,x_{t-1},x_{t}$.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Transition and Emission Probabilities in the HMM}
In advance, all zones are exactely defined. Then, the transition probabilies in matrix $A$ express the likelihood of moving from a beforehand defined zone to another. The connections between zones, retrieved from the floorplan, predetermine these probabilities. Therefore the values in the $n\times n$-matrix $A = (a_{ij})$ are defined as follows:
$$a_{ij} = P(x_{t+1} = z_{j} | x_{t} = z_{i})$$
where $a_{ij}$ represents the transition likelihood from zone $z_{i}$ to zone $z_{j}$. Thus, $\forall i \in \{1,\dots,n\}: \sum_{j=1}^{n} a_{ij} = 1$.\\
The emission probability is the likelihood of observing a particular set of observations $y_{j}$ at zone $z_{i}$. Therefore the values of the $n\times r$-matrix $B = (b_{ij})$ can be written as:
$$b_{ij} = P(y_{j} | z_{i}), \forall y_{j} \in O \land z_{i} \in Z,$$
where $y_{j} = (o_1, o_2, \dots, o_m)_j$ and $o_i$ is the zone prediction result from the $i$-th machine learning algorithm.
Since different individual machine learning methods are used independently, we can assume with good reason that their outcomes are conditionally independent. This leads to the simplified expression:
$$b_{ij} = \prod^{n}_{n=1} P(o_{j} | z_{i})_{n},$$
where $P(o_{j} | z_{i})_{n}$ is the probability of the $n$-th learning method predicting $o_{j}$ at zone $z_{i}$. Therefore it is equal to the sensitivity of the $n$-th machine learning algorithm at zone $z_{i}$:
$$P(o_{j} | z_{i})_{n} = \frac{TP_{n}}{TP_{n} + FN_{n}},$$
with $TP_{n}$ and $FP_{n}$ being the true positive respectively the false positive rate of the corresponding ML algorithm.
%also include the ML specification, (parameter and used methods) maybe in implementation?


%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------

\section{Particle Filter}
We used a particle filter approach to solve the localization problem. This method, also known as Monte Carlo Localization (MCL), is often used for indoor positioning. It combines various noisy measurements to estimate the system state and minimize errors. To introduce the particle filter, we explain in a first paragraph which inputs we fused into the particle filter. The following paragraphs define the different phases in our mathematical model whereas we discuss the different variations of our system in the last subsection.

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Inputs}
As stated above, various measurements are taken into account in our particle filter. The most important inputs are the range estimations between the TAG and ANs, the motion vector measured by the IMU of the TAG and the restrictions given by the floormap. We will refer to $Zd_{t}$ as the range observation vector at time t, which is described as $Zd_{t} = [d^{j}_{t}], j = 1...N,$ where N is the number of ANs. Every distance measurement $d^{j}_{t}$ itself is consisting of various errors, statistically it can be described as: 
$$d^{j}_{t} = \hat{d}^{j}_{t} + d^{j}_{be, t} + \epsilon_{d^{j}, t},$$
where $\hat{d}^{j}_{t}$ is the actual distance to node j, $d^{j}_{be, t}$ is an environmental bias due to local conditions (obstacles) and $\epsilon_{d^{j}, t},$ is a measured random error.

The motion vector $Mv_{t} = [\theta_{t}, \ell_{t}]$ is modeled by the heading direction $\theta$ and the movement length $\ell$. Both of $\theta$ and $\ell$ are calculated by the IMU readings, where again several noises occur such that the heading direction is statistically described as:
$$\theta_{t} = \hat{\theta}_{t} + \theta_{bs,t} + \theta_{be,t} + \epsilon_{\theta, t},$$
with $\hat{\theta}_{t}$ as the actual heading orientation,  $\theta_{bs,t}$ as a sensor bias introduced by uncalibrated sensor readings, $\theta_{be,t}$ as an environmental angular bias due to magnetic field disturbances and $\epsilon_{\theta, t}$ as a measured random error. 
In our implementation we calculated the heading direction with the formula $\theta = atan(\frac{mag_{x}}{mag_{y}})$, where $mag_{x}$ and $mag_{y}$ are low pass filtered magnetometer readings in x and y direction. The update frequency of the sensor was higher than the update frequency of the particle filter, hence we calculated an average of these different measurements, hereafter appearing as $\theta_{t}$ for the average during time period from t-1 to t.

Whereas the heading direction is directly calculated from IMU data, for the stride length we took the previous system state into account. This was necessary, because measured errors propagate over time, so it is almost impossible to use relative quantities (e.g. acceleration) to calculate absolute quantities (e.g. distance) over a longer period of time. As we can not assume the acceleration to be constant, the movement length approximation can be defined as: 
$$\ell_{t} = \hat{\ell}_{t-1} + \sum_{i=0}^{N}([(\hat{a}_{i} + a_{bs,i} +\epsilon_{a, i}) * \Delta t_{i} ]*(N-i)) *\Delta t + \epsilon_{\ell, t},$$
where $\hat{\ell}_{t-1}$ is the actual movement length of time period t-1, $\hat{a}_{i}$ is the actual middle acceleration during the $i$-th of N time slots in time period $\Delta t$, $a_{bs,i}$ is an other sensor bias due to uncalibrated sensor readings and $\epsilon_{a, i}$ as well as $\epsilon_{\ell, t}$ are measured random errors in acceleration and distance respectively.
In our implementation the observed movement length is calculated as follows:
$$\ell_{t} = v_{t-1} * \Delta t + \sum_{i=0}^N [(a_{i} * \Delta t_{i})(N-i)]* \Delta t$$
where $v_{t-1}$ is the velocity of the estimated position change in the last system state update, $a_{i}$ is the $i$-th acceleration measurement and N the number of descrete acceleration measurements during the time period $\Delta t$, which corresponds to the time passed between t-1 and t. As the acceleration sensor - depending on pitch and roll of the device - had a huge non-zero mean noise, we decided to not use the accelerometer data directly, but to use the change in acceleration. To gather the change in acceleration we fed the sensor data into two low pass filters with different parameters, one with a high adaption and one with a low adaption, and only took their difference into account. This corrects a part of the long term sensor bias. 

Although there were many sources of errors, for the likelihood calculation in our work we nevertheless used the actual obtained values $d^{j}_{t}$, $\theta_{t}$ and $\ell_{t}$ since the errors are handled in the likelihood model by fusing different data sources and anchor node distances. However, to compensate the bias and error for the particle spreading, we assumed the heading direction $\theta$ and the stride length $\ell$ as random normal variables whose values are obtained from $\mathcal{N}(\theta_{t}, \sigma_{\theta}^{2})$ and $\mathcal{N}(\ell_{t}, \sigma_{\ell}^{2})$.

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Prediction phase}
Each particle has a state vector that is defined as follows:
$$X_{t} = [x_{t}, y_{t}, x_{t-1}, y_{t-1}]$$
where $(x_{t}, y_{t})$ corresponds to the Cartesian coordinates of the particle at time t and $(x_{t-1}, y_{t-1})$ at time t-1 respectively. In the prediction phase each particle is updated depending of the current movement vector $Mv_{t} = [\theta_{t}, \ell_{t}]$. The coordinates of the particle are updated with the following pattern:
$$[x_{t}, y_{t}]  = [x_{t-1} + \ell_{t} * cos(\theta_{t}),\quad y_{t-1} + \ell_{t} * sin(\theta_{t})]$$
As mentioned in the last subsection, with $\ell_{t}$ and $\theta_{t}$ as random normal variables. In the remainder of this work we will also refer to the motion in Cartesian coordinates as $M_{x,t} = \ell_{t} * cos(\theta_{t})$ for the motion in x-direction and $M_{y,t} = \ell_{t} * sin(\theta_{t})$ for the motion in y-direction.
Floorplan restrictions are applied in this phase, whereas movements through walls are not permitted, they lead to another prediction iteration for that particle.

%-----------------------------------
%	SUBSECTION 3
%-----------------------------------
\subsection{Observation phase}
In the observation phase an associated weight $w^{i}_{t}$ is recalculated for every particle, since the weight does not anymore correspond to the current position. The weight is updated corresponding to the likelihood of the range observations conditioned on each particle $p(Zd_{t} | X^{i}_{t})$ at time t, respectively the likelihood of the motion observation conditioned on each particle $p(Mv_{t} | X^{i}_{t})$ at time t. Then, the probability is determined as:
$$ p(Zd_{t} | X^{i}_{t}) = p(d_{t}^{j} | X^{i}_{t}) $$
and $$ p(Mv_{t} | X^{i}_{t}) = p(M_{x,t} | X^{i}_{t}) * p(M_{y,t} | X^{i}_{t}).$$ %is this correct that p(x) and p(y) are multiplied?
In addition, as defined in subsection 4.3, the zone probability is:
$$ p(y_t | X^{i}_{t}) = p(y_{t} | z^{i}_{t})$$
where $y_t$ is the observed fingerprint at time $t$ and $z^{i}_{t}$ the current zone of particle $X^{i}$.
In order to avoid confusion between different likelihoods used in this work, hereafter we refer to $p(d_{t} | X^{i}_{t})$ as the ranging likelihood, $p(M_{t} | X^{i}_{t})$ for the motion likelihood, $p(y_t | X^{i}_{t})$ for the zone likelihood and $p(Z_{t} | X^{i}_{t})$ as the overall likelihood.

The associated weight $w^{i}_{t}$ of each particle is given by ranging as well as by motion information. A particle at the current position $(x_{t},y_{t})$ with low probability to observe $d_{t}^{j}$ in its position will be assigned a small weight. Additionally a particle that moved in x-direction by $x_{t}^{i}-x_{t-1}^{i}$ with low probability to observe the movement $M_{x,t}$ will also be assigned a small weight. Analogue for the movement in y-direction.
That leads to the fact that particles with large weights will have a stronger effect to the determination of the state of the system.
We assume that all these likelihoods - the ranges to each AN as well as the movement in direction x, y - are statistically independent from each other. Therefore, the overall likelihood is defined as:
$$p(Z_{t} | X^{i}_{t}) = \prod_{j=1}^{N} p(\hat{d}_{j,t}|X_{t}^{i}) * p(\hat{M}_{x,t} | X^{i}_{t}) * p(\hat{M}_{y,t} | X^{i}_{t}) * p(y_t | X^{i}_{t})$$
where $\hat{d}_{j,t}$ is the measured distance to the AN j at time t and $\hat{M}_{x,t}$ is the measured motion in x-direction in timeinterval t, respectively $\hat{M}_{y,t}$ in y-direction and $y_t$ is the measured RSS fingerprint.

The individual likelihood for the range observation can then be expressed as:
$$p(\hat{d}_{j,t} | X^{i}_{t}) = \frac{1}{\sqrt{2\pi \sigma_{j}^{2}}} * exp(\frac{-[\sqrt{(x^{i}_{t}-x_{j})^{2}+(y^{i}_{t}-y_{j})^{2}} - \hat{d}_{j,t}]^{2}}{2\sigma_{j}^{2}})$$
where $(x_{j},y_{j})$ are the known coordinates of the $j$-th AN.
Whereas the individual likelihood of the motion observation in x-direction (analogue for y-direction) is expressed as follows:
$$p(\hat{M}_{x,t} | X^{i}_{t}) = \frac{1}{2\pi \sigma_{Mx}^{2}} * exp(\frac{-[(x^{i}_{t}-x^{i}_{t-1}) - \hat{M}_{x,t}]^{2}}{2\sigma_{Mx}^{2}})$$

%-----------------------------------
%	SUBSECTION 4
%-----------------------------------
\subsection{Resampling phase}
The resampling phase is an essential component of our particle filter implementation, although it is a computationally expensive step. In the resampling, particles with low assigned weights are repositioned at identical positions as particles with high associated weights. This means, that after the repositioning of the prediction phase and the weight calculation in the observation phase, a resampling in systematic manner is done. This resampling relies on the overall likelihood $p(Z_{t} | X^{i}_{t})$, which means that every kind of likelihood is taken into account for this step. After repositioning the particles with low weights (and updating their weight), all weights are normalized to obtain in the next step the weighted center of all particles, which corresponds to the estimated position. 
%-----------------------------------
%	SUBSECTION 5
%-----------------------------------
\subsection{Variants}
We implemented two variants of the particle filter localization system to state the effect on accuracy of the different parts in our system.
Hereafter we will refer to $PF_{full}$ for the full implementation of the particle filter as defined in the last subsection. However, the particles were not spread according to the movement vector, but randomly spread in a box of $2 \times 2$ meters centered on the last estimated position. We decided to cancel the movement vector for spreading, as it caused a very bouncy position estimation.
The second variant $PF_{UWBonly}$ is exclusively using UWB ranging and does not take the IMU measured movement or the fingerprint into account, neither in the prediction phase nor in the observation phase. 


%----------------------------------------------------------------------------------------
%	SECTION 5
%----------------------------------------------------------------------------------------

\section{Experiment Setup}
In our experiment we tested the localization accuracy of the different implemented variants, as well as the accuracy of the indoor tracking system UNISET company provided with their sensors, in a complex indoor scenario with trajectories through numerous of rooms on one floor in a real building of the University of Bern.

%-----------------------------------
%	SUBSECTION 1
%-----------------------------------
\subsection{Zone indication: concrete implementation and parameters}
In our implementation these three completely different ML algorithms were used: KStar \cite{KStar}, Multilayer Perceptron (MLP) \cite{MLP} and the J48 decision tree \cite{J48}. 
The internal parameters of the ML algorithms were optimized from training data, whereas the following parameters were used for the non self optimizing parameters: global percent ratio of 30\% for KStar, single hidden layer with 10 neurons for MLP and a confidence factor of 0.25 for J48.
The zone definition can be seen in figure \ref{fig:zone_definition}.

We assumed that the liklihood of staying in the same zone is bigger than moving to another zone, which led to the empirically defined values for matrix $A$ as:

\begin{figure}[th]
\centering
\includegraphics[width=1.0\textwidth]{Figures/zone_definition}
\decoRule
\caption[Zone Definition]{Zone definition and transitions between zones}
\label{fig:zone_definition}
\end{figure}

\textbf{MATRIX A has to be updated by the correct values}

\setcounter{MaxMatrixCols}{15}
\begin{equation*}
A = 
\begin{pmatrix}
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
0.6 & 0.4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\cr
\end{pmatrix},
\end{equation*}

%-----------------------------------
%	SUBSECTION 2
%-----------------------------------
\subsection{Placement, trajectories and configuration}
We distributed the UWB anchor nodes over several rooms to cover the area of interest homogenously. The exact position is indicated in the floor plan of figure \ref{fig:anchor_position}. Whereas the particle filter updated its state every 700 milliseconds, the IMU sensors were updated every 100 milliseconds. The UWB transmitter of the TAG and the ANs operated in radio mode 3 with a datarate of 6.8 Mbps, they were configured to use channel 1 with a central frequency of 3494.4 MHz and an occupied sprectrum of 500 MHz. \textbf{Anpassen sobald nachgeschaut}

\begin{figure}[th]
\centering
\includegraphics[width=0.8\textwidth]{Figures/anchor_position}
\decoRule
\caption[Anchor Node Positions]{Distributed anchor nodes on the floor map (with distance reference of 10m).}
\label{fig:anchor_position}
\end{figure}

The TAG was hold in the hand of a pedestrian at the starting point of the trajectories, when the experiments started. The pedestrian walked along the given path indicated in figure \ref{fig:trajectory1}, as soon as he passed a predefined checkpoint the current position estimation was registered. The other three trajectories can be seen in appendix \ref{AppendixA}. Every trajectory was tested with every algorithm 4 times.

\begin{figure}[th]
\centering
\includegraphics[width=0.8\textwidth]{Figures/trajectory1}
\decoRule
\caption[Trajectory 1]{Trajectory 1 of the four defined trajectories with the position checkpoints.}
\label{fig:trajectory1}
\end{figure}